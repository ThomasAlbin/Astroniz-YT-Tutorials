{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "082d0884-84ab-44f0-9717-1056e5436246",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ThomasAlbin/Astroniz-YT-Tutorials/blob/main/[ML1]-Asteroid-Spectra/1_data_fetch.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ad2fac",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Abstract\n",
    "\n",
    "This data science and machine learning project is about classifying asteroid taxonomy spectra. We use over 1,000 spectra from [1] to train miscellaneous models to e.g., distinguish between the X class and „non X class“; to perform multi-label classification and unsupervised clustering using autoencoders.\n",
    "\n",
    "# Step 1: Data Fetching\n",
    "\n",
    "This notebook downloads all required asteroid taxonomy data. The data are from [1] and the corresponding classification schema has been defined by [2]. Further, the downloaded files are extracted.\n",
    "\n",
    "## References\n",
    "[1] Url: http://smass.mit.edu/smass.html (Under 2)<br>\n",
    "[2] Bus, Schelte J.; Compositional structure in the asteroid belt: results of a spectroscopic survey; Ph. D. Thesis; Massachusetts Institute of Technology, Dept. of Earth, Atmospheric, and Planetary Sciences; 1999\n",
    "\n",
    "## Further Notes:\n",
    "Further publications:\n",
    "\n",
    "Bus, S. J. and Binzel, R. P. (2002).\n",
    "Phase II of the Small Main-Belt Asteroid Spectroscopic Survey: The Observations,\n",
    "Icarus 158, 106-145<br>\n",
    "Bus, S. J. and Binzel, R. P. (2002).\n",
    "Phase II of the Small Main-Belt Asteroid Spectroscopic Survey: A Feature-Based Taxonomy,\n",
    "Icarus 158, 146-177"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "866de513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import hashlib\n",
    "import os\n",
    "import pathlib\n",
    "import tarfile\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6db64f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's mount the Google Drive, where we store files and models (if applicable, otherwise work\n",
    "# locally)\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/gdrive')\n",
    "    core_path = \"/gdrive/MyDrive/Colab/asteroid_taxonomy/\"\n",
    "except ModuleNotFoundError:\n",
    "    core_path = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f8f0d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to compute the sha256 value of the downloaded files\n",
    "def comp_sha256(file_name):\n",
    "    \"\"\"\n",
    "    Compute the SHA256 hash of a file.\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_name : str\n",
    "        Absolute or relative pathname of the file that shall be parsed.\n",
    "    Returns\n",
    "    -------\n",
    "    sha256_res : str\n",
    "        Resulting SHA256 hash.\n",
    "    \"\"\"\n",
    "    # Set the SHA256 hashing\n",
    "    hash_sha256 = hashlib.sha256()\n",
    "\n",
    "    # Open the file in binary mode (read-only) and parse it in 65,536 byte chunks (in case of\n",
    "    # large files, the loading will not exceed the usable RAM)\n",
    "    with pathlib.Path(file_name).open(mode=\"rb\") as f_temp:\n",
    "        for _seq in iter(lambda: f_temp.read(65536), b\"\"):\n",
    "            hash_sha256.update(_seq)\n",
    "\n",
    "    # Digest the SHA256 result\n",
    "    sha256_res = hash_sha256.hexdigest()\n",
    "\n",
    "    return sha256_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b820e826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the level0 data directory\n",
    "pathlib.Path(os.path.join(core_path, \"data/lvl0/\")).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a6d502c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a dictionary that contains the taxonomy classification data and corresponding sha256 values\n",
    "files_to_dl = \\\n",
    "    {'file1': {'url': 'http://smass.mit.edu/data/smass/Bus.Taxonomy.txt',\n",
    "               'sha256': '0ce970a6972dd7c49d512848b9736d00b621c9d6395a035bd1b4f3780d4b56c6'},\n",
    "     'file2': {'url': 'http://smass.mit.edu/data/smass/smass2data.tar.gz',\n",
    "               'sha256': 'dacf575eb1403c08bdfbffcd5dbfe12503a588e09b04ed19cc4572584a57fa97'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2a363bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the dictionary and download the files\n",
    "for dl_key in files_to_dl:\n",
    "\n",
    "    # Get the URL and create a download filepath by splitting it at the last \"/\"\n",
    "    split = urllib.parse.urlsplit(files_to_dl[dl_key][\"url\"])\n",
    "    filename = pathlib.Path(os.path.join(core_path, \"data/lvl0/\", split.path.split(\"/\")[-1]))\n",
    "\n",
    "    # Download file if it is not available\n",
    "    if not filename.is_file():\n",
    "\n",
    "        print(f\"Downloading now: {files_to_dl[dl_key]['url']}\")\n",
    "\n",
    "        # Download file and retrieve the created filepath\n",
    "        downl_file_path, _ = urllib.request.urlretrieve(url=files_to_dl[dl_key][\"url\"],\n",
    "                                                        filename=filename)\n",
    "\n",
    "        # Compute and compare the hash value\n",
    "        tax_hash = comp_sha256(downl_file_path)\n",
    "        assert tax_hash == files_to_dl[dl_key][\"sha256\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcee6b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untar the spectra data\n",
    "tar = tarfile.open(os.path.join(core_path, \"data/lvl0/\", \"smass2data.tar.gz\"), \"r:gz\")\n",
    "tar.extractall(os.path.join(core_path, \"data/lvl0/\"))\n",
    "tar.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
